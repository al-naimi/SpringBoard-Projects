{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Omar Al-Naimi\n",
    "\n",
    "### This project is for developing logistic regression model for predicting patients' readmission within 30 days after discharge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing data set = Hospital-Readmission.csv\n",
    "import pandas as pd\n",
    "my_dataset = pd.read_csv ('C:\\\\Users\\\\omar_\\\\Desktop\\\\Springboard DataScience\\\\Capstone Project\\\\my 1st project\\\\project progress\\\\Data_SecondarySource\\\\Hospital-Readmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>PatientInsuranceNO.</th>\n",
       "      <th>Surname</th>\n",
       "      <th>SES-CreditScore</th>\n",
       "      <th>HospitalLocation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AdmisionPeriod/day</th>\n",
       "      <th>PreviousExpenses</th>\n",
       "      <th>NumOfPrevious admissions</th>\n",
       "      <th>HealthInsurance</th>\n",
       "      <th>RegularCheckup</th>\n",
       "      <th>EstimatedExpenses</th>\n",
       "      <th>Readmited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>15737173</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>497</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15632264</td>\n",
       "      <td>Kay</td>\n",
       "      <td>476</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>15691483</td>\n",
       "      <td>Chin</td>\n",
       "      <td>549</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>15600882</td>\n",
       "      <td>Scott</td>\n",
       "      <td>635</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>15643966</td>\n",
       "      <td>Goforth</td>\n",
       "      <td>616</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>15737452</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>653</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>15788218</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>549</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>15661507</td>\n",
       "      <td>Muldrow</td>\n",
       "      <td>587</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>15568982</td>\n",
       "      <td>Hao</td>\n",
       "      <td>726</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>15577657</td>\n",
       "      <td>McDonald</td>\n",
       "      <td>732</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170886.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>15597945</td>\n",
       "      <td>Dellucci</td>\n",
       "      <td>636</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138555.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>15699309</td>\n",
       "      <td>Gerasimov</td>\n",
       "      <td>510</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118913.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>15725737</td>\n",
       "      <td>Mosman</td>\n",
       "      <td>669</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8487.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>15625047</td>\n",
       "      <td>Yen</td>\n",
       "      <td>846</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>187616.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>15738191</td>\n",
       "      <td>Maclean</td>\n",
       "      <td>577</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124508.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>15736816</td>\n",
       "      <td>Young</td>\n",
       "      <td>756</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>136815.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170041.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>15700772</td>\n",
       "      <td>Nebechi</td>\n",
       "      <td>571</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38433.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>15728693</td>\n",
       "      <td>McWilliams</td>\n",
       "      <td>574</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>141349.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100187.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>15656300</td>\n",
       "      <td>Lucciano</td>\n",
       "      <td>411</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>59697.17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53483.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>9971</td>\n",
       "      <td>15587133</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>518</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>151027.05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119377.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>9972</td>\n",
       "      <td>15721377</td>\n",
       "      <td>Chou</td>\n",
       "      <td>833</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>144751.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166472.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9973</td>\n",
       "      <td>15747927</td>\n",
       "      <td>Ch'in</td>\n",
       "      <td>758</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>155739.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171552.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>9974</td>\n",
       "      <td>15806455</td>\n",
       "      <td>Miller</td>\n",
       "      <td>611</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157474.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>9975</td>\n",
       "      <td>15695474</td>\n",
       "      <td>Barker</td>\n",
       "      <td>583</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>122531.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13549.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9976</td>\n",
       "      <td>15666295</td>\n",
       "      <td>Smith</td>\n",
       "      <td>610</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>113957.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196526.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>9977</td>\n",
       "      <td>15656062</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>637</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>103377.81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84419.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>9978</td>\n",
       "      <td>15579969</td>\n",
       "      <td>Mancini</td>\n",
       "      <td>683</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24991.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>9979</td>\n",
       "      <td>15703563</td>\n",
       "      <td>P'eng</td>\n",
       "      <td>774</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>93017.47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>191608.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>9980</td>\n",
       "      <td>15692664</td>\n",
       "      <td>Diribe</td>\n",
       "      <td>677</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>90022.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2988.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>9981</td>\n",
       "      <td>15719276</td>\n",
       "      <td>T'ao</td>\n",
       "      <td>741</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>74371.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99595.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>9982</td>\n",
       "      <td>15672754</td>\n",
       "      <td>Burbidge</td>\n",
       "      <td>498</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>152039.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53445.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>9983</td>\n",
       "      <td>15768163</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>655</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>137145.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115146.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>9984</td>\n",
       "      <td>15656710</td>\n",
       "      <td>Cocci</td>\n",
       "      <td>613</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151325.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>9985</td>\n",
       "      <td>15696175</td>\n",
       "      <td>Echezonachukwu</td>\n",
       "      <td>602</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>90602.42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51695.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>9987</td>\n",
       "      <td>15581736</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>673</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>183579.54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34047.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>9988</td>\n",
       "      <td>15588839</td>\n",
       "      <td>Mancini</td>\n",
       "      <td>606</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>180307.73</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1914.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>9989</td>\n",
       "      <td>15589329</td>\n",
       "      <td>Pirozzi</td>\n",
       "      <td>775</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49337.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>9990</td>\n",
       "      <td>15605622</td>\n",
       "      <td>McMillan</td>\n",
       "      <td>841</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179436.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>9991</td>\n",
       "      <td>15798964</td>\n",
       "      <td>Nkemakonam</td>\n",
       "      <td>714</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>35016.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53667.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>9992</td>\n",
       "      <td>15769959</td>\n",
       "      <td>Ajuluchukwu</td>\n",
       "      <td>597</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>88381.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69384.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>9993</td>\n",
       "      <td>15657105</td>\n",
       "      <td>Chukwualuka</td>\n",
       "      <td>726</td>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>195192.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>9994</td>\n",
       "      <td>15569266</td>\n",
       "      <td>Rahman</td>\n",
       "      <td>644</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>155060.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29179.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>9995</td>\n",
       "      <td>15719294</td>\n",
       "      <td>Wood</td>\n",
       "      <td>800</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167773.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  PatientInsuranceNO.         Surname  SES-CreditScore  \\\n",
       "0             1             15634602        Hargrave              619   \n",
       "1             2             15647311            Hill              608   \n",
       "2             3             15619304            Onio              502   \n",
       "3             4             15701354            Boni              699   \n",
       "4             5             15737888        Mitchell              850   \n",
       "5             6             15574012             Chu              645   \n",
       "6             7             15592531        Bartlett              822   \n",
       "7             8             15656148          Obinna              376   \n",
       "8             9             15792365              He              501   \n",
       "9            10             15592389              H?              684   \n",
       "10           11             15767821          Bearce              528   \n",
       "11           12             15737173         Andrews              497   \n",
       "12           13             15632264             Kay              476   \n",
       "13           14             15691483            Chin              549   \n",
       "14           15             15600882           Scott              635   \n",
       "15           16             15643966         Goforth              616   \n",
       "16           17             15737452           Romeo              653   \n",
       "17           18             15788218       Henderson              549   \n",
       "18           19             15661507         Muldrow              587   \n",
       "19           20             15568982             Hao              726   \n",
       "20           21             15577657        McDonald              732   \n",
       "21           22             15597945        Dellucci              636   \n",
       "22           23             15699309       Gerasimov              510   \n",
       "23           24             15725737          Mosman              669   \n",
       "24           25             15625047             Yen              846   \n",
       "25           26             15738191         Maclean              577   \n",
       "26           27             15736816           Young              756   \n",
       "27           28             15700772         Nebechi              571   \n",
       "28           29             15728693      McWilliams              574   \n",
       "29           30             15656300        Lucciano              411   \n",
       "...         ...                  ...             ...              ...   \n",
       "9970       9971             15587133        Thompson              518   \n",
       "9971       9972             15721377            Chou              833   \n",
       "9972       9973             15747927           Ch'in              758   \n",
       "9973       9974             15806455          Miller              611   \n",
       "9974       9975             15695474          Barker              583   \n",
       "9975       9976             15666295           Smith              610   \n",
       "9976       9977             15656062         Azikiwe              637   \n",
       "9977       9978             15579969         Mancini              683   \n",
       "9978       9979             15703563           P'eng              774   \n",
       "9979       9980             15692664          Diribe              677   \n",
       "9980       9981             15719276            T'ao              741   \n",
       "9981       9982             15672754        Burbidge              498   \n",
       "9982       9983             15768163         Griffin              655   \n",
       "9983       9984             15656710           Cocci              613   \n",
       "9984       9985             15696175  Echezonachukwu              602   \n",
       "9985       9986             15586914          Nepean              659   \n",
       "9986       9987             15581736        Bartlett              673   \n",
       "9987       9988             15588839         Mancini              606   \n",
       "9988       9989             15589329         Pirozzi              775   \n",
       "9989       9990             15605622        McMillan              841   \n",
       "9990       9991             15798964      Nkemakonam              714   \n",
       "9991       9992             15769959     Ajuluchukwu              597   \n",
       "9992       9993             15657105     Chukwualuka              726   \n",
       "9993       9994             15569266          Rahman              644   \n",
       "9994       9995             15719294            Wood              800   \n",
       "9995       9996             15606229        Obijiaku              771   \n",
       "9996       9997             15569892       Johnstone              516   \n",
       "9997       9998             15584532             Liu              709   \n",
       "9998       9999             15682355       Sabbatini              772   \n",
       "9999      10000             15628319          Walker              792   \n",
       "\n",
       "     HospitalLocation  Gender  Age  AdmisionPeriod/day  PreviousExpenses  \\\n",
       "0           Manhattan  Female   42                   2              0.00   \n",
       "1        StatenIsland  Female   41                   1          83807.86   \n",
       "2           Manhattan  Female   42                   8         159660.80   \n",
       "3           Manhattan  Female   39                   1              0.00   \n",
       "4        StatenIsland  Female   43                   2         125510.82   \n",
       "5        StatenIsland    Male   44                   8         113755.78   \n",
       "6           Manhattan    Male   50                   7              0.00   \n",
       "7               Bronx  Female   29                   4         115046.74   \n",
       "8           Manhattan    Male   44                   4         142051.07   \n",
       "9           Manhattan    Male   27                   2         134603.88   \n",
       "10          Manhattan    Male   31                   6         102016.72   \n",
       "11       StatenIsland    Male   24                   3              0.00   \n",
       "12          Manhattan  Female   34                  10              0.00   \n",
       "13          Manhattan  Female   25                   5              0.00   \n",
       "14       StatenIsland  Female   35                   7              0.00   \n",
       "15              Bronx    Male   45                   3         143129.41   \n",
       "16              Bronx    Male   58                   1         132602.88   \n",
       "17       StatenIsland  Female   24                   9              0.00   \n",
       "18       StatenIsland    Male   45                   6              0.00   \n",
       "19          Manhattan  Female   24                   6              0.00   \n",
       "20          Manhattan    Male   41                   8              0.00   \n",
       "21       StatenIsland  Female   32                   8              0.00   \n",
       "22       StatenIsland  Female   38                   4              0.00   \n",
       "23          Manhattan    Male   46                   3              0.00   \n",
       "24          Manhattan  Female   38                   5              0.00   \n",
       "25          Manhattan    Male   25                   3              0.00   \n",
       "26              Bronx    Male   36                   2         136815.64   \n",
       "27          Manhattan    Male   44                   9              0.00   \n",
       "28              Bronx  Female   43                   3         141349.43   \n",
       "29          Manhattan    Male   29                   0          59697.17   \n",
       "...               ...     ...  ...                 ...               ...   \n",
       "9970        Manhattan    Male   42                   7         151027.05   \n",
       "9971        Manhattan  Female   34                   3         144751.81   \n",
       "9972        Manhattan    Male   26                   4         155739.76   \n",
       "9973        Manhattan    Male   27                   7              0.00   \n",
       "9974        Manhattan    Male   33                   7         122531.86   \n",
       "9975            Bronx    Male   50                   1         113957.01   \n",
       "9976        Manhattan  Female   33                   7         103377.81   \n",
       "9977        Manhattan  Female   32                   9              0.00   \n",
       "9978        Manhattan    Male   40                   9          93017.47   \n",
       "9979        Manhattan  Female   58                   1          90022.85   \n",
       "9980     StatenIsland    Male   35                   6          74371.49   \n",
       "9981            Bronx    Male   42                   3         152039.70   \n",
       "9982            Bronx  Female   46                   7         137145.12   \n",
       "9983        Manhattan    Male   40                   4              0.00   \n",
       "9984            Bronx    Male   35                   7          90602.42   \n",
       "9985        Manhattan    Male   36                   6         123841.49   \n",
       "9986            Bronx    Male   47                   1         183579.54   \n",
       "9987     StatenIsland    Male   30                   8         180307.73   \n",
       "9988        Manhattan    Male   30                   4              0.00   \n",
       "9989     StatenIsland    Male   28                   4              0.00   \n",
       "9990            Bronx    Male   33                   3          35016.60   \n",
       "9991        Manhattan  Female   53                   4          88381.21   \n",
       "9992     StatenIsland    Male   36                   2              0.00   \n",
       "9993        Manhattan    Male   28                   7         155060.41   \n",
       "9994        Manhattan  Female   29                   2              0.00   \n",
       "9995        Manhattan    Male   39                   5              0.00   \n",
       "9996        Manhattan    Male   35                  10          57369.61   \n",
       "9997        Manhattan  Female   36                   7              0.00   \n",
       "9998            Bronx    Male   42                   3          75075.31   \n",
       "9999        Manhattan  Female   28                   4         130142.79   \n",
       "\n",
       "      NumOfPrevious admissions  HealthInsurance  RegularCheckup  \\\n",
       "0                            1                1               1   \n",
       "1                            1                0               1   \n",
       "2                            3                1               0   \n",
       "3                            2                0               0   \n",
       "4                            1                1               1   \n",
       "5                            2                1               0   \n",
       "6                            2                1               1   \n",
       "7                            4                1               0   \n",
       "8                            2                0               1   \n",
       "9                            1                1               1   \n",
       "10                           2                0               0   \n",
       "11                           2                1               0   \n",
       "12                           2                1               0   \n",
       "13                           2                0               0   \n",
       "14                           2                1               1   \n",
       "15                           2                0               1   \n",
       "16                           1                1               0   \n",
       "17                           2                1               1   \n",
       "18                           1                0               0   \n",
       "19                           2                1               1   \n",
       "20                           2                1               1   \n",
       "21                           2                1               0   \n",
       "22                           1                1               0   \n",
       "23                           2                0               1   \n",
       "24                           1                1               1   \n",
       "25                           2                0               1   \n",
       "26                           1                1               1   \n",
       "27                           2                0               0   \n",
       "28                           1                1               1   \n",
       "29                           2                1               1   \n",
       "...                        ...              ...             ...   \n",
       "9970                         2                1               0   \n",
       "9971                         1                0               0   \n",
       "9972                         1                1               0   \n",
       "9973                         2                1               1   \n",
       "9974                         1                1               0   \n",
       "9975                         2                1               0   \n",
       "9976                         1                1               0   \n",
       "9977                         2                1               1   \n",
       "9978                         2                1               0   \n",
       "9979                         1                0               1   \n",
       "9980                         1                0               0   \n",
       "9981                         1                1               1   \n",
       "9982                         1                1               0   \n",
       "9983                         1                0               0   \n",
       "9984                         2                1               1   \n",
       "9985                         2                1               0   \n",
       "9986                         2                0               1   \n",
       "9987                         2                1               1   \n",
       "9988                         2                1               0   \n",
       "9989                         2                1               1   \n",
       "9990                         1                1               0   \n",
       "9991                         1                1               0   \n",
       "9992                         1                1               0   \n",
       "9993                         1                1               0   \n",
       "9994                         2                0               0   \n",
       "9995                         2                1               0   \n",
       "9996                         1                1               1   \n",
       "9997                         1                0               1   \n",
       "9998                         2                1               0   \n",
       "9999                         1                1               0   \n",
       "\n",
       "      EstimatedExpenses  Readmited  \n",
       "0             101348.88          1  \n",
       "1             112542.58          0  \n",
       "2             113931.57          1  \n",
       "3              93826.63          0  \n",
       "4              79084.10          0  \n",
       "5             149756.71          1  \n",
       "6              10062.80          0  \n",
       "7             119346.88          1  \n",
       "8              74940.50          0  \n",
       "9              71725.73          0  \n",
       "10             80181.12          0  \n",
       "11             76390.01          0  \n",
       "12             26260.98          0  \n",
       "13            190857.79          0  \n",
       "14             65951.65          0  \n",
       "15             64327.26          0  \n",
       "16              5097.67          1  \n",
       "17             14406.41          0  \n",
       "18            158684.81          0  \n",
       "19             54724.03          0  \n",
       "20            170886.17          0  \n",
       "21            138555.46          0  \n",
       "22            118913.53          1  \n",
       "23              8487.75          0  \n",
       "24            187616.16          0  \n",
       "25            124508.29          0  \n",
       "26            170041.95          0  \n",
       "27             38433.35          0  \n",
       "28            100187.43          0  \n",
       "29             53483.21          0  \n",
       "...                 ...        ...  \n",
       "9970          119377.36          0  \n",
       "9971          166472.81          0  \n",
       "9972          171552.02          0  \n",
       "9973          157474.10          0  \n",
       "9974           13549.24          0  \n",
       "9975          196526.55          1  \n",
       "9976           84419.78          0  \n",
       "9977           24991.92          0  \n",
       "9978          191608.97          0  \n",
       "9979            2988.28          0  \n",
       "9980           99595.67          0  \n",
       "9981           53445.17          1  \n",
       "9982          115146.40          1  \n",
       "9983          151325.24          0  \n",
       "9984           51695.41          0  \n",
       "9985           96833.00          0  \n",
       "9986           34047.54          0  \n",
       "9987            1914.41          0  \n",
       "9988           49337.84          0  \n",
       "9989          179436.60          0  \n",
       "9990           53667.08          0  \n",
       "9991           69384.71          1  \n",
       "9992          195192.40          0  \n",
       "9993           29179.52          0  \n",
       "9994          167773.55          0  \n",
       "9995           96270.64          0  \n",
       "9996          101699.77          0  \n",
       "9997           42085.58          1  \n",
       "9998           92888.52          1  \n",
       "9999           38190.78          0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking my_dataset. it is 10,000 rows and 14 columns\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RowNumber', 'PatientInsuranceNO.', 'Surname', 'SES-CreditScore',\n",
      "       'HospitalLocation', 'Gender', 'Age', 'AdmisionPeriod/day',\n",
      "       'PreviousExpenses', 'NumOfPrevious admissions', 'HealthInsurance',\n",
      "       'RegularCheckup', 'EstimatedExpenses', 'Readmited'],\n",
      "      dtype='object')\n",
      "Total Rows = 10000  : Total Columns = 14\n"
     ]
    }
   ],
   "source": [
    "# More checking about data set\n",
    "rows= len (my_dataset)\n",
    "columns= len (my_dataset.columns)\n",
    "print (my_dataset.columns)\n",
    "print (\"Total Rows =\", rows, \" : Total Columns =\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber                   10000 non-null int64\n",
      "PatientInsuranceNO.         10000 non-null int64\n",
      "Surname                     10000 non-null object\n",
      "SES-CreditScore             10000 non-null int64\n",
      "HospitalLocation            10000 non-null object\n",
      "Gender                      10000 non-null object\n",
      "Age                         10000 non-null int64\n",
      "AdmisionPeriod/day          10000 non-null int64\n",
      "PreviousExpenses            10000 non-null float64\n",
      "NumOfPrevious admissions    10000 non-null int64\n",
      "HealthInsurance             10000 non-null int64\n",
      "RegularCheckup              10000 non-null int64\n",
      "EstimatedExpenses           10000 non-null float64\n",
      "Readmited                   10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#columns information shows correct data types, numbers, and non-null\n",
    "my_dataset.info ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>37.000</td>\n",
       "      <td>44.0000</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SES-CreditScore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>350.00</td>\n",
       "      <td>584.00</td>\n",
       "      <td>652.000</td>\n",
       "      <td>718.0000</td>\n",
       "      <td>850.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdmisionPeriod/day</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreviousExpenses</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97198.540</td>\n",
       "      <td>127644.2400</td>\n",
       "      <td>250898.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfPrevious admissions</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedExpenses</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.11</td>\n",
       "      <td>100193.915</td>\n",
       "      <td>149388.2475</td>\n",
       "      <td>199992.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count           mean           std     min  \\\n",
       "Age                       10000.0      38.921800     10.487806   18.00   \n",
       "SES-CreditScore           10000.0     650.528800     96.653299  350.00   \n",
       "AdmisionPeriod/day        10000.0       5.012800      2.892174    0.00   \n",
       "PreviousExpenses          10000.0   76485.889288  62397.405202    0.00   \n",
       "NumOfPrevious admissions  10000.0       1.530200      0.581654    1.00   \n",
       "EstimatedExpenses         10000.0  100090.239881  57510.492818   11.58   \n",
       "\n",
       "                               25%         50%          75%        max  \n",
       "Age                          32.00      37.000      44.0000      92.00  \n",
       "SES-CreditScore             584.00     652.000     718.0000     850.00  \n",
       "AdmisionPeriod/day            3.00       5.000       7.0000      10.00  \n",
       "PreviousExpenses              0.00   97198.540  127644.2400  250898.09  \n",
       "NumOfPrevious admissions      1.00       1.000       2.0000       4.00  \n",
       "EstimatedExpenses         51002.11  100193.915  149388.2475  199992.48  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data description (descriptive statistics) for important numerical columns\n",
    "# subsetting columns\n",
    "columns_subset= my_dataset [['Age','SES-CreditScore', 'AdmisionPeriod/day', 'PreviousExpenses', 'NumOfPrevious admissions', \\\n",
    "             'EstimatedExpenses']]\n",
    "columns_subset.describe ().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B test visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams ['figure.figsize'] =8,4\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')\n",
    "plt.style.use (\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data subsets & visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This subset is for gender\n",
    "\n",
    "male = my_dataset ['Gender'] =='Male'\n",
    "female = my_dataset ['Gender'] =='Female'\n",
    "admitted = my_dataset ['Readmited'] == 1\n",
    "not_admitted = my_dataset ['Readmited'] == 0\n",
    "\n",
    "male_admitted = my_dataset [male & admitted]\n",
    "male_not_admitted = my_dataset [male & not_admitted]\n",
    "female_admitted = my_dataset [female & admitted]\n",
    "female_not_admitted = my_dataset [female & not_admitted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualization for gender\n",
    "\n",
    "vis1 = male_admitted ['Gender'].value_counts()\n",
    "vis2 = male_not_admitted ['Gender'].value_counts()\n",
    "vis3 = female_admitted ['Gender'].value_counts()\n",
    "vis4 = female_not_admitted ['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAD8CAYAAACIGfYpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAxEwAEAMNB/A22wPfCogxVeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1589a0749b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing the numbers of Males vs Females\n",
    "\n",
    "plt.style.use (\"ggplot\")\n",
    "from collections import Counter\n",
    "c = Counter(my_dataset.Gender)\n",
    "\n",
    "men = c['Male']\n",
    "women = c['Female']\n",
    "\n",
    "bar_heights = (men, women)\n",
    "x_axis = (1,2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.8\n",
    "\n",
    "ax.bar(x_axis, bar_heights, width)\n",
    "\n",
    "ax.set_xlim((0, 3))\n",
    "ax.set_ylim((0, max(men, women)*1.1))\n",
    "\n",
    "ax.set_xticks([i+width/20 for i in x_axis])\n",
    "ax.set_xticklabels(['Male', 'Female'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEaCAYAAADucwUCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1589a06c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the actual numbers\n",
    "\n",
    "A = [vis1, vis3]\n",
    "B = [vis2, vis4]\n",
    "\n",
    "x_axis = (1,2)\n",
    "\n",
    "plt.bar(x_axis, A, color = 'b', width= 0.5)\n",
    "plt.bar(x_axis, B, color = 'r', bottom = A, width= 0.5)\n",
    "\n",
    "plt.title ('Gender')\n",
    "\n",
    "plt.xticks ([i+width/20 for i in x_axis])\n",
    "plt.xlabel ('Readmitted=blue , No-Readmission=red')\n",
    "plt.xticks(x_axis)\n",
    "plt.xticks([1, 2], ['MALE', 'FEMALE'])\n",
    "plt.legend (loc= 1,bbox_to_anchor=(0.5, -0.05),  shadow=True, ncol=2 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEaCAYAAADe/xQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTOz/AREWKnbPun0YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x158995ccfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the percent\n",
    "pool1 = vis1+vis2\n",
    "vis1p = vis1 *100/pool1\n",
    "vis2p = vis2*100/pool1\n",
    "pool2 = vis3 +vis4\n",
    "vis3p = vis3*100/pool2\n",
    "vis4p = vis4*100/pool2\n",
    "A = [vis1p, vis3p]\n",
    "B = [vis2p, vis4p]\n",
    "\n",
    "x_axis = (1,2)\n",
    "\n",
    "plt.title ('% Gender')\n",
    "plt.bar(x_axis, A, color = 'b')\n",
    "plt.bar(x_axis, B, color = 'r', bottom = A)\n",
    "plt.xlabel ('% of Readmission: Readmitted=blue , No-Readmission=red')\n",
    "\n",
    "plt.xticks ([i+width/20 for i in x_axis])\n",
    "plt.xticks(x_axis)\n",
    "plt.xticks([1, 2], ['MALE', 'FEMALE'])\n",
    "plt.legend (loc= 1,bbox_to_anchor=(0.5, -0.05),  shadow=True, ncol=2 )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other parameters can be visualized by the same method above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# Data Preprocessing\n",
    "# 1) Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HospitalLocation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>PreviousExpenses</th>\n",
       "      <th>EstimatedExpenses</th>\n",
       "      <th>RegularCheckup</th>\n",
       "      <th>Readmited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StatenIsland</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HospitalLocation  Gender  Age  PreviousExpenses  EstimatedExpenses  \\\n",
       "0        Manhattan  Female   42              0.00          101348.88   \n",
       "1     StatenIsland  Female   41          83807.86          112542.58   \n",
       "2        Manhattan  Female   42         159660.80          113931.57   \n",
       "3        Manhattan  Female   39              0.00           93826.63   \n",
       "4     StatenIsland  Female   43         125510.82           79084.10   \n",
       "\n",
       "   RegularCheckup  Readmited  \n",
       "0               1          1  \n",
       "1               1          0  \n",
       "2               0          1  \n",
       "3               0          0  \n",
       "4               1          0  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Importing or selecting the important columns of the dataset\n",
    "# subsetting columns\n",
    "dataset = my_dataset [['HospitalLocation', 'Gender', 'Age', 'PreviousExpenses', \\\n",
    "                       'EstimatedExpenses', 'RegularCheckup', 'Readmited']]\n",
    "dataset.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating matrix of features to identify the dependent factor vs independent factors (parameters)\n",
    "X = dataset.iloc[:, [0, 1, 2, 3, 4, 5]].values  # X = independent factors which are all columns except the last one\n",
    "y = dataset.iloc[:, 6].values   # y = the dependent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Manhattan', 'Female', 42, 0.0, 101348.88, 1],\n",
       "       ['StatenIsland', 'Female', 41, 83807.86, 112542.58, 1],\n",
       "       ['Manhattan', 'Female', 42, 159660.8, 113931.57, 0],\n",
       "       ..., \n",
       "       ['Manhattan', 'Female', 36, 0.0, 42085.58, 1],\n",
       "       ['Bronx', 'Male', 42, 75075.31, 92888.52, 0],\n",
       "       ['Manhattan', 'Female', 28, 130142.79, 38190.78, 0]], dtype=object)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Taking care of missing data. Filling the missed data by the mean of the column\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X[:, 2:5])\n",
    "X[:, 2:5] = imputer.transform(X[:, 2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Encoding categorical data\n",
    "\n",
    "# a) Encoding the Independent Variable/s\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # OneHotEncoder is for dummy encoding the encoded \n",
    "                                                              # variable by LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [[0, 1]])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "\n",
    "# b) Encoding the Dependent Variable. Because it is already encoded, no need for y encoding\n",
    "# labelencoder_y = LabelEncoder()\n",
    "# y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4     5          6          7    8\n",
       "0  0.0  1.0  0.0  1.0  0.0  42.0       0.00  101348.88  1.0\n",
       "1  0.0  0.0  1.0  1.0  0.0  41.0   83807.86  112542.58  1.0\n",
       "2  0.0  1.0  0.0  1.0  0.0  42.0  159660.80  113931.57  0.0\n",
       "3  0.0  1.0  0.0  1.0  0.0  39.0       0.00   93826.63  0.0\n",
       "4  0.0  0.0  1.0  1.0  0.0  43.0  125510.82   79084.10  1.0\n",
       "5  0.0  0.0  1.0  0.0  1.0  44.0  113755.78  149756.71  0.0\n",
       "6  0.0  1.0  0.0  0.0  1.0  50.0       0.00   10062.80  1.0\n",
       "7  1.0  0.0  0.0  1.0  0.0  29.0  115046.74  119346.88  0.0\n",
       "8  0.0  1.0  0.0  0.0  1.0  44.0  142051.07   74940.50  1.0\n",
       "9  0.0  1.0  0.0  0.0  1.0  27.0  134603.88   71725.73  1.0"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame (X).head (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) # you can ommit random_state. It \n",
    "# keeps the same random sample for all sampling trials OR you can choose different value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6) Feature Scaling. This for bringing large and small values of different parameters on the same scale.\n",
    "\"\"\" a) No need to feature scale the y (dependent) variable in binary outcome (logistic regression).Do it when the outcome is\n",
    "continuous (linear regression).\n",
    "\n",
    "b) There are 2 feature scaling methods, Standardization and Normalization.\n",
    "Xstand = X - mean(X) / standard deviation(X)\n",
    "Xnorm = X - min(X) / max(X) - min(X)\n",
    "\n",
    "c) Even thought most python and R ML libraries do features scaling for you, some are not and then it is required to do it\n",
    "manually. It is good practice to include feature scaling code in your script to remind youself this important processing step\n",
    "\n",
    "d) Important note: feature scaling to dummy independent variables improve the model but loss the interpretation. Whereas, you\n",
    "should not feature scale the dummy dependant variable\"\"\"\n",
    " \n",
    "# Here we will use Standardisation Scale.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) # X_train needs for fit and transform\n",
    "X_test = sc_X.transform(X_test)       # X_test needs for only transform\n",
    "\n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)\n",
    "# y_test = sc_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Fitting classifier to the Training set\n",
    "# A) Fitting Logistic Regression to the Training set\n",
    "# Creating logestic regression class (classifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1534,   61],\n",
       "       [ 312,   93]])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82646692,  0.80774032,  0.82125   ,  0.80875   ,  0.8075    ,\n",
       "        0.78875   ,  0.82875   ,  0.8       ,  0.79849812,  0.81852315])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B) Fitting KNN to the Training set\n",
    "# Creating KNN class (classifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1479,  116],\n",
       "       [ 238,  167]])"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82771536,  0.80774032,  0.8125    ,  0.815     ,  0.805     ,\n",
       "        0.80125   ,  0.8225    ,  0.8125    ,  0.80350438,  0.82853567])"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C) Fitting SVC to the Training set. The assumption is that the data is linearly separable.\n",
    "# Creating SVC class (classifier)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1595,    0],\n",
       "       [ 405,    0]])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79525593,  0.79525593,  0.79625   ,  0.79625   ,  0.79625   ,\n",
       "        0.79625   ,  0.79625   ,  0.79625   ,  0.79599499,  0.79599499])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D) Fitting kernel SVC to the Training set. The assumption is that the data is NOT-linearly separable.\n",
    "# Creating kernel SVC class (classifier)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1569,   26],\n",
       "       [ 307,   98]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84269663,  0.8289638 ,  0.83125   ,  0.83      ,  0.84      ,\n",
       "        0.825     ,  0.84      ,  0.82375   ,  0.81977472,  0.83979975])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E) Fitting Naive Bayes to the Training set.\n",
    "# Creating Naive Bayes class (classifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB ()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1425,  170],\n",
       "       [ 259,  146]])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79525593,  0.79775281,  0.78875   ,  0.79      ,  0.7975    ,\n",
       "        0.7925    ,  0.81      ,  0.7825    ,  0.78222778,  0.8097622 ])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F) Fitting Decision Tree Classification to the Training set. It does not need for features scaling because it is not\n",
    "# Euclidean-based algorithm.\n",
    "# Creating Decision Tree Classification class (classifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier (criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1366,  229],\n",
       "       [ 223,  182]])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76404494,  0.75031211,  0.7625    ,  0.75125   ,  0.77375   ,\n",
       "        0.72375   ,  0.75625   ,  0.74625   ,  0.74468085,  0.77346683])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# G) Fitting Random Forest Classification to the Training set. It does not need for features scaling because it is not\n",
    "# Euclidean-based algorithm.\n",
    "# Creating Random Forest Classification class (classifier)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier (n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1495,  100],\n",
       "       [ 265,  140]])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82646692,  0.80774032,  0.82125   ,  0.80875   ,  0.8075    ,\n",
       "        0.78875   ,  0.82875   ,  0.8       ,  0.79849812,  0.81852315])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score (estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 9) Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Expenses')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualising the Test set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Expenses')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
